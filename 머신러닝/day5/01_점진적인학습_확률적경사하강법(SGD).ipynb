{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "970ddd2b",
   "metadata": {},
   "source": [
    "## 점진적인 학습 이란\n",
    "##### - 훈련에 필요한 데이터가 한번에 다 수집된 경우가 아니라,\n",
    "##### - 시간 차를 두고 수집이 되는 경우에는 훈련모델 학습은 언제 해야 할까?\n",
    "##### - 이런 문제를 해결하기 위해 수집될 때 마다 학습을 계속 이어나가는 훈련방식을\n",
    "##### - \"점진적인 학습\" 이라고 합니다.\n",
    "##### -->> \"점진적인 학습\" 또는 온라인 학습이라고 칭함\n",
    "##### - 대표적인 점진적 학습 알고리즘은 \"확률적 경사하강법\" 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d59592",
   "metadata": {},
   "source": [
    "## 확률적 경사 하강법(SGD; Stochastic Gradient Descent)\n",
    "##### - 경사 란 : 우리가 흔히 사용하는 단어인 경사(기울기) 입니다.\n",
    "##### - 하강법 이란 : 내려가는 방법 입니다.\n",
    "##### - 경사 하강법 이란 ?\n",
    "##### ... : 원하는 지점에 도달하기 위해 가장 가파른 경사를 따라 내려가는 방법을 찾는 방법\n",
    "##### - 확률적 이란 : \"무작위하게\" 또는 \"랜덤하게\"의 기술적 표현 언어 입니다.\n",
    "#####  : 훈련데이터의 전체 특성들 중에서 하나씩 랜덤하게 선택하여 가장 가파른 길을 찾음\n",
    "## <확률적 경사 하강법 순서>\n",
    "##### 1. 훈련데이터에서 랜덤하게 하나의 특성을 선택\n",
    "##### 2. 선택한 특성을 이용하여 경사를 조금씩(아주조금씩) 내려갑니다.\n",
    "##### 3. 내려 갈 수 있을 때 까지 내려갑니다.\n",
    "##### 4. 훈련 세트에서 다른 특성을 랜덤하게 또 다시 하나 선택 \n",
    "##### 4. 선택된 특성을 이용해서 경사를 조금씩 내려갈 수 있을 때 까지 내려간다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb876509",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41367195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58f9ec0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diagonal</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bream</td>\n",
       "      <td>242.0</td>\n",
       "      <td>25.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.5200</td>\n",
       "      <td>4.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bream</td>\n",
       "      <td>290.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>31.2</td>\n",
       "      <td>12.4800</td>\n",
       "      <td>4.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bream</td>\n",
       "      <td>340.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>12.3778</td>\n",
       "      <td>4.6961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bream</td>\n",
       "      <td>363.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>12.7300</td>\n",
       "      <td>4.4555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bream</td>\n",
       "      <td>430.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.4440</td>\n",
       "      <td>5.1340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Species  Weight  Length  Diagonal   Height   Width\n",
       "0   Bream   242.0    25.4      30.0  11.5200  4.0200\n",
       "1   Bream   290.0    26.3      31.2  12.4800  4.3056\n",
       "2   Bream   340.0    26.5      31.1  12.3778  4.6961\n",
       "3   Bream   363.0    29.0      33.5  12.7300  4.4555\n",
       "4   Bream   430.0    29.0      34.0  12.4440  5.1340"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fish = pd.read_csv(\"./data/07_fish.csv\")\n",
    "print(len(fish))\n",
    "fish.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b9a27c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159 entries, 0 to 158\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Species   159 non-null    object \n",
      " 1   Weight    159 non-null    float64\n",
      " 2   Length    159 non-null    float64\n",
      " 3   Diagonal  159 non-null    float64\n",
      " 4   Height    159 non-null    float64\n",
      " 5   Width     159 non-null    float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 7.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "fish.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e3e9fd",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a99b1b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159, 5)\n",
      "(159,)\n"
     ]
    }
   ],
   "source": [
    "### 독립변수와 종속변수 분리하여 변수화\n",
    "# 독립변수명 : fish_input\n",
    "# 종속변수명 : fish_target\n",
    "\n",
    "## 분리시켜 주세요...\n",
    "### 독립변수 입력 데이터 추출(2차원 배열 형태로)\n",
    "fish_input = fish[['Weight','Length','Diagonal','Height','Width']].to_numpy()\n",
    "print(fish_input.shape)\n",
    "\n",
    "### 종속변수 타겟 데이터 추출(1차원 배열 형태로)\n",
    "fish_target = fish['Species'].to_numpy()\n",
    "print(fish_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee792d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련-입력 (119, 5)\n",
      "훈련-타겟 (119,)\n",
      "테스트-입력 (40, 5)\n",
      "테스트-타겟 (40,)\n"
     ]
    }
   ],
   "source": [
    "### 훈련(입력, 타겟), 테스트(입력, 타겟) 데이터 분류하기\n",
    "### 훈련데이터(입력, 타겟)와 테스트데이터(입력, 타겟) 분류\n",
    "# 훈련 : 테스트 = 75 : 25\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 순서 : 입력 먼저, 타겟 다음\n",
    "train_input, test_input, train_target, test_target = train_test_split(\n",
    "    fish_input, fish_target, test_size=0.25, random_state=42)\n",
    "\n",
    "print(\"훈련-입력\", train_input.shape)\n",
    "print(\"훈련-타겟\", train_target.shape)\n",
    "print(\"테스트-입력\", test_input.shape)\n",
    "print(\"테스트-타겟\", test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "575ce2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 정규화(표준화) -> 독립변수 표준점수로 동일하게 표준화(스케일)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c97d755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f538e141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8066a469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b780bdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.19657820e-01  6.09431747e-01  8.10412209e-01  1.85194896e+00\n",
      "   1.00075672e+00]\n",
      " [ 3.00412188e-01  1.54653445e+00  1.45316551e+00 -4.69816625e-01\n",
      "   2.72917446e-01]\n",
      " [-1.08585360e+00 -1.68646987e+00 -1.70848587e+00 -1.70159849e+00\n",
      "  -2.00447580e+00]\n",
      " [-7.97341433e-01 -6.08801762e-01 -6.74869070e-01 -8.24805885e-01\n",
      "  -2.76314705e-01]\n",
      " [-7.12898847e-01 -7.30625113e-01 -7.00926637e-01 -8.02298036e-02\n",
      "  -7.03386897e-01]\n",
      " [-9.12746301e-01 -9.64900787e-01 -9.52816444e-01 -8.80171862e-01\n",
      "  -9.91535662e-01]\n",
      " [-7.97341433e-01 -7.02512032e-01 -7.61727625e-01 -7.82824547e-01\n",
      "  -5.44530184e-01]\n",
      " [ 6.38182533e-01  5.62576612e-01  7.32239510e-01  1.64473401e+00\n",
      "   5.07057367e-01]\n",
      " [-7.41046376e-01 -6.74398951e-01 -7.35670058e-01 -6.12059278e-01\n",
      "  -5.57331377e-01]\n",
      " [-8.67710255e-01 -7.96222301e-01 -8.92015456e-01 -9.33586942e-01\n",
      "  -1.02183182e+00]\n",
      " [ 8.21141469e-01  7.49997152e-01  6.71438522e-01  4.98470601e-01\n",
      "   1.47257213e+00]\n",
      " [ 3.00412188e-01  2.34590667e-01  4.28234570e-01  1.36042157e+00\n",
      "   2.23297582e-01]\n",
      " [ 3.39818728e-01  4.03269153e-01  2.37145751e-01  2.88316959e-01\n",
      "   9.56866916e-01]\n",
      " [-5.44013674e-01 -5.15091492e-01 -4.75094395e-01  3.66303469e-01\n",
      "  -4.78329727e-01]\n",
      " [ 1.70778862e+00  1.45282418e+00  1.33156354e+00  8.95515284e-01\n",
      "   1.91866324e+00]\n",
      " [ 9.02769303e-01  7.03142017e-01  8.88584908e-01  1.89027545e+00\n",
      "   8.55371741e-01]\n",
      " [-1.08247590e+00 -1.61150165e+00 -1.62162731e+00 -1.70006740e+00\n",
      "  -1.92815631e+00]\n",
      " [ 1.70778862e+00  1.35911391e+00  1.20996156e+00  7.58211612e-01\n",
      "   1.72445085e+00]\n",
      " [-7.97341433e-01 -7.21254086e-01 -7.09612492e-01 -6.65474358e-01\n",
      "  -6.41636379e-01]\n",
      " [ 1.03379487e-01  4.71701274e-02  2.37145751e-01  8.84451967e-01\n",
      "   4.17997636e-01]\n",
      " [ 1.76563061e-01  1.31225877e+00  1.23601913e+00 -3.90792929e-01\n",
      "  -7.66770476e-02]\n",
      " [ 1.49668216e+00  1.03112796e+00  1.21864741e+00  2.44274986e+00\n",
      "   1.40289707e+00]\n",
      " [ 1.56705098e+00  2.17439325e+00  2.06986125e+00  1.57345974e-02\n",
      "   1.05025467e+00]\n",
      " [-4.03276031e-01 -9.33952774e-02 -2.05832877e-01 -3.90101472e-01\n",
      "   7.18777527e-02]\n",
      " [-6.28456261e-01 -7.30625113e-01 -7.00926637e-01  1.31751261e-01\n",
      "  -6.32675543e-01]\n",
      " [ 2.30043366e-01  2.34590667e-01  4.28234570e-01  1.33360290e+00\n",
      "   3.99832133e-01]\n",
      " [-6.98825082e-01 -5.43204573e-01 -6.14068082e-01 -7.18444929e-01\n",
      "  -4.98811636e-01]\n",
      " [-2.62538387e-01  8.24965367e-01  7.40925366e-01 -6.35667608e-01\n",
      "  -2.61197105e-01]\n",
      " [-4.25794054e-01 -2.90186844e-01 -1.10288467e-01  6.56271044e-01\n",
      "  -2.61075189e-01]\n",
      " [ 7.22625119e-01  9.84272826e-01  8.79899053e-01  5.61590778e-01\n",
      "   9.47723207e-01]\n",
      " [-7.69193904e-01 -8.89932571e-01 -8.65957890e-01 -1.16136195e-01\n",
      "  -9.32772089e-01]\n",
      " [-6.98825082e-01 -6.08801762e-01 -6.05382227e-01 -5.50346711e-01\n",
      "  -5.48919164e-01]\n",
      " [-7.55120140e-01 -7.02512032e-01 -7.61727625e-01 -7.82824547e-01\n",
      "  -4.75952362e-01]\n",
      " [ 1.28557569e+00  7.03142017e-01  8.97270764e-01  1.98228866e+00\n",
      "   1.06683526e+00]\n",
      " [-1.10696425e+00 -7.49367167e-01 -7.35670058e-01 -5.89537525e-01\n",
      "  -6.68518884e-01]\n",
      " [ 1.25742816e+00  6.09431747e-01  5.23778980e-01  6.48467454e-01\n",
      "   2.04051841e+00]\n",
      " [ 9.33731584e-01  6.09431747e-01  8.36469776e-01  1.85150445e+00\n",
      "   9.78324154e-01]\n",
      " [ 8.07067705e-01  6.09431747e-01  8.10412209e-01  1.63137406e+00\n",
      "   1.02550570e+00]\n",
      " [ 8.35215234e-01  7.96852286e-01  6.97496089e-01  4.22089260e-01\n",
      "   1.16936672e+00]\n",
      " [-8.81784019e-01 -8.89932571e-01 -9.61502300e-01 -7.96826558e-01\n",
      "  -8.52246487e-01]\n",
      " [-7.69193904e-01 -7.96222301e-01 -7.87785191e-01 -6.53546719e-01\n",
      "  -5.32826236e-01]\n",
      " [ 3.39664035e+00  2.95218849e+00  2.84290238e+00  1.82128867e-01\n",
      "   1.03367408e+00]\n",
      " [-3.61054738e-01 -9.33952774e-02 -2.05832877e-01 -4.47196092e-01\n",
      "  -6.90572897e-02]\n",
      " [-1.07262426e+00 -1.52716241e+00 -1.55214047e+00 -1.67235972e+00\n",
      "  -1.86207776e+00]\n",
      " [-1.35874508e-01  9.37417691e-01  8.45155631e-01 -6.09095890e-01\n",
      "  -2.87287156e-01]\n",
      " [-6.56603789e-01 -5.61946627e-01 -5.44581239e-01 -6.08108094e-01\n",
      "  -3.95182929e-01]\n",
      " [ 1.28557569e+00  1.07798310e+00  9.58071752e-01  7.57174426e-01\n",
      "   1.62033448e+00]\n",
      " [-9.52152841e-01 -1.29288673e+00 -1.28287895e+00 -4.97598394e-01\n",
      "  -1.29339999e+00]\n",
      " [-1.01689216e+00 -1.38659700e+00 -1.43922435e+00 -1.31734577e+00\n",
      "  -1.49291573e+00]\n",
      " [ 1.63741980e+00  1.17169337e+00  1.27076255e+00  2.41341232e+00\n",
      "   1.40143407e+00]\n",
      " [-2.06243329e-01  1.40880397e-01  2.86852201e-02 -3.07916828e-01\n",
      "   1.97085615e-01]\n",
      " [-1.07966115e+00 -1.63961473e+00 -1.67374245e+00 -1.64628190e+00\n",
      "  -1.87036806e+00]\n",
      " [ 1.98926391e+00  1.26540364e+00  1.15784643e+00  9.72415218e-01\n",
      "   1.47525429e+00]\n",
      " [-9.38079077e-01 -1.21791852e+00 -1.20470625e+00 -5.64348722e-01\n",
      "  -1.30089783e+00]\n",
      " [-1.05151362e+00 -1.33037084e+00 -1.39579507e+00 -1.47914678e+00\n",
      "  -1.45146425e+00]\n",
      " [-6.98825082e-01 -4.21381222e-01 -5.01151962e-01 -6.14281820e-01\n",
      "  -3.79943413e-01]\n",
      " [-5.52457933e-01 -2.71444790e-01 -3.70864130e-01 -5.68349296e-01\n",
      "  -1.27577031e-01]\n",
      " [-3.41351467e-01 -1.40250412e-01 -5.81733343e-02 -7.27225524e-02\n",
      "   1.98304776e-01]\n",
      " [ 1.59674544e-01  1.12767316e-01  2.97946739e-01  1.17051775e+00\n",
      "   2.92058277e-01]\n",
      " [ 8.63362763e-01  7.96852286e-01  7.06181944e-01  4.87110945e-01\n",
      "   1.10718950e+00]\n",
      " [ 1.20113311e+00  1.07798310e+00  9.75443463e-01  5.61195660e-01\n",
      "   1.32993026e+00]\n",
      " [-6.53789036e-01 -4.77607384e-01 -3.96921696e-01 -4.80855248e-01\n",
      "  -4.98080139e-01]\n",
      " [-9.94374134e-01 -1.34911289e+00 -1.30893652e+00 -1.16443491e+00\n",
      "  -1.32906046e+00]\n",
      " [-8.67710255e-01 -8.33706409e-01 -9.09387167e-01 -9.19856575e-01\n",
      "  -8.60414868e-01]\n",
      " [-8.25488962e-01 -9.83642841e-01 -1.04836085e+00 -8.98915295e-01\n",
      "  -6.86806303e-01]\n",
      " [ 1.56705098e+00  1.17169337e+00  1.32287768e+00  2.16352457e+00\n",
      "   1.17174409e+00]\n",
      " [-7.12898847e-01 -5.61946627e-01 -5.44581239e-01 -5.71065736e-01\n",
      "  -6.84733729e-01]\n",
      " [-9.21062831e-03  1.40880397e-01  3.24004305e-01  9.40262452e-01\n",
      "   1.47343835e-01]\n",
      " [-6.84751318e-01 -6.08801762e-01 -5.70638805e-01 -7.55166253e-01\n",
      "  -4.22979805e-01]\n",
      " [-3.38536715e-01 -3.27670952e-01 -2.84005576e-01  5.49589054e-01\n",
      "  -1.85487191e-01]\n",
      " [ 1.42631334e+00  1.07798310e+00  9.75443463e-01  7.08130345e-01\n",
      "   1.69263074e+00]\n",
      " [ 4.58038349e-01  5.62576612e-01  4.54292136e-01  3.44250919e-01\n",
      "   1.18210696e+00]\n",
      " [-7.41046376e-01 -5.61946627e-01 -6.31439793e-01 -7.42448377e-01\n",
      "  -5.02469120e-01]\n",
      " [-7.83267669e-01 -7.02512032e-01 -7.61727625e-01 -7.27261010e-01\n",
      "  -6.95401390e-01]\n",
      " [ 3.25590271e+00  2.95218849e+00  2.84290238e+00  1.82128867e-01\n",
      "   1.03367408e+00]\n",
      " [ 3.53737799e+00  3.27080341e+00  3.19033660e+00  4.81431116e-01\n",
      "   1.84807380e+00]\n",
      " [-7.26972611e-01 -6.08801762e-01 -6.74869070e-01 -7.37756345e-01\n",
      "  -5.62817603e-01]\n",
      " [ 1.59674544e-01  1.40880397e-01  3.32690160e-01  1.26991474e+00\n",
      "   2.41097337e-01]\n",
      " [ 8.63362763e-01  7.03142017e-01  6.10637534e-01  4.31325154e-01\n",
      "   1.39747180e+00]\n",
      " [-1.49948272e-01  3.28300937e-01  5.23778980e-01  1.24719543e+00\n",
      "   3.80691302e-01]\n",
      " [ 1.14483805e+00  7.40626125e-01  7.23553655e-01  7.15835155e-01\n",
      "   1.29554992e+00]\n",
      " [ 4.13002303e-01  1.35911391e+00  1.26207669e+00 -2.65836710e-01\n",
      "   4.15315481e-01]\n",
      " [-8.52089559e-02  4.71701274e-02  1.93716473e-01  9.55079395e-01\n",
      "   4.39717660e-03]\n",
      " [ 8.63362763e-01  4.22011207e-01  6.28009245e-01  1.50034290e+00\n",
      "   4.56706006e-01]\n",
      " [-8.62080749e-01 -8.14964355e-01 -7.87785191e-01 -8.01567980e-01\n",
      "  -7.76414657e-01]\n",
      " [-1.09035721e+00 -1.88326143e+00 -1.95168982e+00 -1.66702562e+00\n",
      "  -1.85329980e+00]\n",
      " [ 1.06039546e+00  1.82766526e+00  1.73111289e+00 -2.92013309e-01\n",
      "   5.65516150e-01]\n",
      " [ 3.00412188e-01  1.12767316e-01  2.80575028e-01  1.31303204e+00\n",
      "   5.06082038e-01]\n",
      " [ 1.03379487e-01  8.90562556e-01  8.01726354e-01 -3.88323439e-01\n",
      "   7.81564332e-02]\n",
      " [-8.53636490e-01 -1.01175592e+00 -9.96245722e-01 -3.59874908e-01\n",
      "  -1.08218030e+00]\n",
      " [-9.21062831e-03  3.00187856e-01  3.24004305e-01  1.53729727e-01\n",
      "   5.52714956e-01]\n",
      " [-2.62538387e-01  1.90570465e-02 -1.01602612e-01 -3.15424079e-01\n",
      "   1.14060733e-01]\n",
      " [-5.44013674e-01 -4.68236357e-01 -3.88235841e-01 -3.61949280e-01\n",
      "  -1.95728145e-01]\n",
      " [-1.07262426e+00 -1.45219419e+00 -1.51739705e+00 -1.62627903e+00\n",
      "  -1.94607798e+00]\n",
      " [ 4.13002303e-01  2.34590667e-01  2.37145751e-01  4.64638581e-01\n",
      "   1.28847878e+00]\n",
      " [-6.31271013e-01 -4.21381222e-01 -3.53492419e-01 -3.27969091e-01\n",
      "  -3.73725690e-01]\n",
      " [-7.41046376e-01 -6.08801762e-01 -6.74869070e-01 -6.79723318e-01\n",
      "  -5.62817603e-01]\n",
      " [ 8.21141469e-01  5.15721477e-01  6.88810233e-01  1.76102232e+00\n",
      "   5.62102498e-01]\n",
      " [-2.45649870e-01 -4.65401424e-02 -4.08016234e-02 -2.08632519e-02\n",
      "   1.42223358e-01]\n",
      " [-1.07937967e+00 -1.54590446e+00 -1.56951218e+00 -1.64420753e+00\n",
      "  -2.01154694e+00]\n",
      " [-2.62538387e-01  5.15721477e-01  5.67208257e-01 -7.79046226e-01\n",
      "  -1.76953062e-01]\n",
      " [-8.87413525e-01 -9.08674625e-01 -8.74643745e-01 -8.11692891e-01\n",
      "  -9.41123344e-01]\n",
      " [-1.07937967e+00 -1.62087268e+00 -1.63899902e+00 -1.67413775e+00\n",
      "  -1.93303295e+00]\n",
      " [-2.90685916e-01 -2.05847601e-01 -6.05820169e-03  8.93342132e-01\n",
      "  -8.69789603e-02]\n",
      " [-2.90685916e-01 -2.33960682e-01 -1.79775310e-01  3.53531430e-03\n",
      "   2.95728568e-02]\n",
      " [-2.62538387e-01  6.09431747e-01  6.54066812e-01 -7.22593673e-01\n",
      "  -3.89440064e-02]\n",
      " [-3.75128502e-01 -9.33952774e-02 -2.05832877e-01 -4.18648782e-01\n",
      "  -6.90572897e-02]\n",
      " [-6.00308732e-01 -3.27670952e-01 -4.14293407e-01 -5.98353606e-01\n",
      "  -4.66199072e-01]\n",
      " [ 1.42631334e+00  9.84272826e-01  8.79899053e-01  5.61590778e-01\n",
      "   1.85624218e+00]\n",
      " [-7.69193904e-01 -6.08801762e-01 -6.74869070e-01 -7.95789372e-01\n",
      "  -5.62817603e-01]\n",
      " [-9.94374134e-01 -1.26477365e+00 -1.32630823e+00 -1.24424885e+00\n",
      "  -1.22908923e+00]\n",
      " [ 1.75000992e+00  1.07798310e+00  9.66757607e-01  8.68844787e-01\n",
      "   1.83734518e+00]\n",
      " [-1.05095067e+00 -1.26477365e+00 -1.30893652e+00 -1.46447801e+00\n",
      "  -1.56606541e+00]\n",
      " [ 5.11518653e-01  5.15721477e-01  7.14867800e-01  1.54738669e+00\n",
      "   6.83470002e-01]\n",
      " [-2.62538387e-01 -2.33960682e-01 -1.97147021e-01  6.18734788e-01\n",
      "  -1.30624934e-01]\n",
      " [-4.03276031e-01 -4.65401424e-02 -1.62403600e-01 -2.57341662e-01\n",
      "  -1.48790437e-01]\n",
      " [ 5.81887475e-01  3.28300937e-01  5.15093125e-01  1.50439286e+00\n",
      "   4.40430204e-01]\n",
      " [-6.84751318e-01 -5.61946627e-01 -6.31439793e-01 -5.11304066e-01\n",
      "  -5.02469120e-01]\n",
      " [-2.62538387e-01 -1.12137331e-01 -2.23204588e-01 -1.33225070e-01\n",
      "   4.20009252e-01]]\n",
      "[[-0.88741352 -0.91804565 -1.03098914 -0.90464451 -0.80762518]\n",
      " [-1.06924656 -1.50842035 -1.54345461 -1.58849582 -1.93803151]\n",
      " [-0.54401367  0.35641402  0.30663259 -0.8135697  -0.65388895]\n",
      " [-0.34698097 -0.23396068 -0.22320459 -0.11905019 -0.12233464]\n",
      " [-0.68475132 -0.51509149 -0.58801052 -0.8998784  -0.50124996]\n",
      " [ 1.70778862  0.79685229  0.98412932  2.49283113  1.31347159]\n",
      " [-1.08726098 -1.67709884 -1.70848587 -1.76175528 -2.01154694]\n",
      " [-0.60030873 -0.3089289  -0.29269143 -0.43855288 -0.33056738]\n",
      " [-0.57779071 -0.36515506 -0.44035097 -0.52577528 -0.17219833]\n",
      " [ 2.41147684  2.57734741  2.4694106   0.45038962  1.54627043]\n",
      " [ 0.72262512  0.46886634  0.64538096  1.38570915  0.7798447 ]\n",
      " [ 1.70778862  1.0779831   1.06230202  0.86222655  1.2659243 ]\n",
      " [ 0.58188748  0.32830094  0.51509312  1.62381742  0.6898706 ]\n",
      " [-0.68475132 -0.7962223  -0.77041348  0.0074865  -0.70436223]\n",
      " [ 0.86336276  0.60943175  0.80172635  1.82199404  0.69535682]\n",
      " [ 1.48260839  0.93741769  1.11441715  2.26561331  1.13260901]\n",
      " [ 1.70778862  1.40596904  1.2794484   0.92396381  2.25161618]\n",
      " [-0.49334812 -0.18710555 -0.28400558 -0.41845122 -0.18548719]\n",
      " [-0.47364485 -0.42138122 -0.50115196 -0.38758259 -0.44212064]\n",
      " [ 0.86336276  0.42201121  0.61063753  1.48117965  0.51028814]\n",
      " [-1.07881672 -1.56464651 -1.57819804 -1.64186151 -1.92900972]\n",
      " [ 0.610035    0.46886634  0.6366951   1.67197249  0.41787572]\n",
      " [ 0.30041219  0.2814458   0.44560628  1.20923936 -0.04894113]\n",
      " [ 0.30041219  0.20647759  0.42823457  1.32466334  0.31156486]\n",
      " [ 1.58112475  0.93741769  1.10573129  2.27724461  1.12389201]\n",
      " [ 1.98926391  1.35911391  1.23601913  0.90136798  1.80936543]\n",
      " [-0.62845626 -0.46823636 -0.54458124 -0.63897672 -0.44090148]\n",
      " [-0.34698097 -0.18710555 -0.17108946 -0.17708322 -0.12178601]\n",
      " [-1.0881054  -1.75206705 -1.77797271 -1.75918701 -2.07299266]\n",
      " [-1.0790982  -1.56464651 -1.57819804 -1.64186151 -2.00087927]\n",
      " [ 0.32855972  1.31225877  1.23601913 -0.50315475  0.00653071]\n",
      " [-0.90993155 -1.039869   -1.10916184 -1.05557977 -0.9185079 ]\n",
      " [-0.96200448 -1.15232133 -1.22207796 -1.0544932  -1.10741694]\n",
      " [ 0.48900063  1.64024472  1.5139665  -0.26435502  0.25706835]\n",
      " [-0.14994827 -0.18710555 -0.01474406  0.86810394  0.15106228]\n",
      " [-0.7691939  -0.60880176 -0.67486907 -0.67972332 -0.63444333]\n",
      " [-0.65660379 -0.56194663 -0.51852367 -0.45169057 -0.38280844]\n",
      " [-0.7691939  -0.70251203 -0.65749736 -0.67858735 -0.70344785]\n",
      " [-0.69882508 -0.6556569  -0.62275394  0.21581272 -0.78708232]\n",
      " [ 1.20113311  0.98427283  0.8712132   0.88131571  1.76968173]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 표준화 객체 생성하기\n",
    "ss = StandardScaler()\n",
    "\n",
    "# 스스로 표준점수 생성\n",
    "ss.fit(train_input)\n",
    "\n",
    "# 훈련 및 테스트 입력 데이터 표준점수로 변환하기\n",
    "# - 타겟 데이터는 절대 변경하면 안됩니다.(정답입니다.)\n",
    "train_scaled = ss.transform(train_input)\n",
    "test_scaled = ss.transform(test_input)\n",
    "\n",
    "print(train_scaled)\n",
    "print(test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23efb2e",
   "metadata": {},
   "source": [
    "## 확률적 경사 하강법을 이용한 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca733967",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 객체(모델) 생성하기\n",
    "# - loss : 손실함수 (log=로지스틱 손실함수 사용)\n",
    "#        : 조금씩 내려오면서 손실이 작은쪽을 찾아서 내려오기 위한 방법\n",
    "#        : 사람은 손실이 작은 값들을 알 수 없습니다.\n",
    "#          (학습모델이 가지고 있는 손실 계산식을 통해 결정합니다.)\n",
    "#        : 분류 결과에 만족한다면, 다 내려왔다고 인정해야 함\n",
    "#        : 사람이 직접 만들거나 직접 계산하지는 않음(관여하지 않음)\n",
    "#        : 훈련모델이 직접 수행\n",
    "#        : 사람은 분류 성격에 맞게 사용할 손실함수를 지정만 합니다.\n",
    "# - max_iter : 훈련 반복 횟수 \n",
    "#            (전체 특성이 다 끝나면 1회로 본다 -> 이를 \"에포크\"라 함)\n",
    "#        : 훈련 반복 회수가 부족한 경우 다 내려오기 전에 끝..?\n",
    "#        : 분류 정확도가 낮아질수도(과소적합), 높아질수도(과대적합)\n",
    "#        : 가장 적합한 반복 시점(에포크)을 찾아야 함..\n",
    "#          (에포크는 사람이 찾아서 max_iter에 넣어 줄 수 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d395c39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.773109243697479\n",
      "0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### 사용 클래스(모델) : SGDClassifier\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# 클래스(모델)생성\n",
    "sc = SGDClassifier(loss=\"log\", max_iter=10, random_state=42)\n",
    "\n",
    "### 훈련모델 생성하기\n",
    "sc.fit(train_scaled, train_target)\n",
    "\n",
    "### 훈련모델 분류 정확도 확인하기\n",
    "# - 과적합 여부 확인을 위해 훈련 및 테스트 데이터 모두확인\n",
    "print(sc.score(train_scaled, train_target))\n",
    "print(sc.score(test_scaled, test_target))\n",
    "\n",
    "### (해석)\n",
    "# - 훈련모델의 학습능력이 다소 떨어집니다.\n",
    "# - 이는 훈련 및 테스트 모두 과소적합을 보인다고 할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d9f3fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9663865546218487\n",
      "0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### 점진적 학습 시작\n",
    "# 새로운 데이터가 들어왔다고 가정..(실제로는 새로운 데이터 사용)\n",
    "sc.partial_fit(train_scaled, train_target)\n",
    "\n",
    "print(sc.score(train_scaled, train_target))\n",
    "print(sc.score(test_scaled, test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c73bf3",
   "metadata": {},
   "source": [
    "## 에포크 반복획수 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "819f462c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sc = SGDClassifier(loss=\"log\", random_state=42)\n",
    "\n",
    "train_score = []\n",
    "test_score = []\n",
    "\n",
    "# 범주 고유값\n",
    "classes = np.unique(train_target)\n",
    "\n",
    "# 반복을 300회 이상으로 테스트하여 정확도를 리스트에 저장\n",
    "for _ in range(0, 300) :\n",
    "    sc.partial_fit(train_scaled, train_target, classes=classes)\n",
    "    \n",
    "    train_score.append(sc.score(train_scaled, train_target))\n",
    "    test_score.append(sc.score(test_scaled, test_target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1154bceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 정확도 리스트 갯수 =  300\n",
      "테스트 정확도 리스트 갯수 =  300\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 정확도 리스트 갯수 = \", len(train_score))\n",
    "print(\"테스트 정확도 리스트 갯수 = \", len(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87d55de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 최적의 에포크 위치확인하기 : 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_score, label=\"train_score\")\n",
    "plt.plot(test_score, label=\"test_score\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa9e4667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.957983193277311\n",
      "0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### 최적의 에포크값을 이용해서 처음부터 훈련 시작\n",
    "### 사용 클래스(모델) : SGDClassifier\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# 클래스(모델)생성\n",
    "# tol=None : 훈련모델 스스로 만족하더라도, 훈련 종료하지 못하게하기..\n",
    "#          : 무조건 100번 반복하기..\n",
    "sc = SGDClassifier(loss=\"log\", max_iter=100, tol=None, random_state=42)\n",
    "\n",
    "### 훈련모델 생성하기\n",
    "sc.fit(train_scaled, train_target)\n",
    "\n",
    "### 훈련모델 분류 정확도 확인하기\n",
    "# - 과적합 여부 확인을 위해 훈련 및 테스트 데이터 모두확인\n",
    "print(sc.score(train_scaled, train_target))\n",
    "print(sc.score(test_scaled, test_target))\n",
    "\n",
    "### (해석)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9caa627",
   "metadata": {},
   "source": [
    "## 모델 예측값 데이터프레임에 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf08b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### [문제]\n",
    "##### - 새로운 데이터가 수집되었다고 가정하고 예측을 통해 결과값 저장하기\n",
    "# - 기존 fish 데이터 전체를 신규데이터라고 가정하고 진행\n",
    "# - 신규 데이터는 Weight, Length, Diagonal, Height, Width\n",
    "#   (데이터프레임 변수는 별도로 만들어서 사용)\n",
    "\n",
    "##### - 데이터프레임에 예측결과에 대한 Species_pred 컬럼 추가\n",
    "\n",
    "##### <출력 결과>\n",
    "# - Species_pred가 추가된 데이터프레임 출력\n",
    "#   (출력결과) 데이터프레임의 7개 컬럼 모두 출력\n",
    "#   Weight, Length, Diagonal, Height, Width, Species, Species_pred\n",
    "\n",
    "# - 정답을 맞춘 갯수와 틀린 갯수 출력하기\n",
    "#   (출력 예시) 총 갯수[159]건 중에, 정답갯수[149]건, 오답 갯수[10]건\n",
    "\n",
    "# - 정답률과 오답률 출력하기\n",
    "#   (출력 예시) 총 100.0% 중 정답률[93.71%], 오답률[6.29%]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7775fb46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.42000e+02, 2.54000e+01, 3.00000e+01, 1.15200e+01, 4.02000e+00],\n",
       "       [2.90000e+02, 2.63000e+01, 3.12000e+01, 1.24800e+01, 4.30560e+00],\n",
       "       [3.40000e+02, 2.65000e+01, 3.11000e+01, 1.23778e+01, 4.69610e+00],\n",
       "       [3.63000e+02, 2.90000e+01, 3.35000e+01, 1.27300e+01, 4.45550e+00],\n",
       "       [4.30000e+02, 2.90000e+01, 3.40000e+01, 1.24440e+01, 5.13400e+00],\n",
       "       [4.50000e+02, 2.97000e+01, 3.47000e+01, 1.36024e+01, 4.92740e+00],\n",
       "       [5.00000e+02, 2.97000e+01, 3.45000e+01, 1.41795e+01, 5.27850e+00],\n",
       "       [3.90000e+02, 3.00000e+01, 3.50000e+01, 1.26700e+01, 4.69000e+00],\n",
       "       [4.50000e+02, 3.00000e+01, 3.51000e+01, 1.40049e+01, 4.84380e+00],\n",
       "       [5.00000e+02, 3.07000e+01, 3.62000e+01, 1.42266e+01, 4.95940e+00],\n",
       "       [4.75000e+02, 3.10000e+01, 3.62000e+01, 1.42628e+01, 5.10420e+00],\n",
       "       [5.00000e+02, 3.10000e+01, 3.62000e+01, 1.43714e+01, 4.81460e+00],\n",
       "       [5.00000e+02, 3.15000e+01, 3.64000e+01, 1.37592e+01, 4.36800e+00],\n",
       "       [3.40000e+02, 3.20000e+01, 3.73000e+01, 1.39129e+01, 5.07280e+00],\n",
       "       [6.00000e+02, 3.20000e+01, 3.72000e+01, 1.49544e+01, 5.17080e+00],\n",
       "       [6.00000e+02, 3.20000e+01, 3.72000e+01, 1.54380e+01, 5.58000e+00],\n",
       "       [7.00000e+02, 3.30000e+01, 3.83000e+01, 1.48604e+01, 5.28540e+00],\n",
       "       [7.00000e+02, 3.30000e+01, 3.85000e+01, 1.49380e+01, 5.19750e+00],\n",
       "       [6.10000e+02, 3.35000e+01, 3.86000e+01, 1.56330e+01, 5.13380e+00],\n",
       "       [6.50000e+02, 3.35000e+01, 3.87000e+01, 1.44738e+01, 5.72760e+00],\n",
       "       [5.75000e+02, 3.40000e+01, 3.95000e+01, 1.51285e+01, 5.56950e+00],\n",
       "       [6.85000e+02, 3.40000e+01, 3.92000e+01, 1.59936e+01, 5.37040e+00],\n",
       "       [6.20000e+02, 3.45000e+01, 3.97000e+01, 1.55227e+01, 5.28010e+00],\n",
       "       [6.80000e+02, 3.50000e+01, 4.06000e+01, 1.54686e+01, 6.13060e+00],\n",
       "       [7.00000e+02, 3.50000e+01, 4.05000e+01, 1.62405e+01, 5.58900e+00],\n",
       "       [7.25000e+02, 3.50000e+01, 4.09000e+01, 1.63600e+01, 6.05320e+00],\n",
       "       [7.20000e+02, 3.50000e+01, 4.06000e+01, 1.63618e+01, 6.09000e+00],\n",
       "       [7.14000e+02, 3.60000e+01, 4.15000e+01, 1.65170e+01, 5.85150e+00],\n",
       "       [8.50000e+02, 3.60000e+01, 4.16000e+01, 1.68896e+01, 6.19840e+00],\n",
       "       [1.00000e+03, 3.70000e+01, 4.26000e+01, 1.89570e+01, 6.60300e+00],\n",
       "       [9.20000e+02, 3.85000e+01, 4.41000e+01, 1.80369e+01, 6.30630e+00],\n",
       "       [9.55000e+02, 3.85000e+01, 4.40000e+01, 1.80840e+01, 6.29200e+00],\n",
       "       [9.25000e+02, 3.95000e+01, 4.53000e+01, 1.87542e+01, 6.74970e+00],\n",
       "       [9.75000e+02, 4.10000e+01, 4.59000e+01, 1.86354e+01, 6.74730e+00],\n",
       "       [9.50000e+02, 4.10000e+01, 4.65000e+01, 1.76235e+01, 6.37050e+00],\n",
       "       [4.00000e+01, 1.41000e+01, 1.62000e+01, 4.14720e+00, 2.26800e+00],\n",
       "       [6.90000e+01, 1.82000e+01, 2.03000e+01, 5.29830e+00, 2.82170e+00],\n",
       "       [7.80000e+01, 1.88000e+01, 2.12000e+01, 5.57560e+00, 2.90440e+00],\n",
       "       [8.70000e+01, 1.98000e+01, 2.22000e+01, 5.61660e+00, 3.17460e+00],\n",
       "       [1.20000e+02, 2.00000e+01, 2.22000e+01, 6.21600e+00, 3.57420e+00],\n",
       "       [0.00000e+00, 2.05000e+01, 2.28000e+01, 6.47520e+00, 3.35160e+00],\n",
       "       [1.10000e+02, 2.08000e+01, 2.31000e+01, 6.16770e+00, 3.39570e+00],\n",
       "       [1.20000e+02, 2.10000e+01, 2.37000e+01, 6.11460e+00, 3.29430e+00],\n",
       "       [1.50000e+02, 2.20000e+01, 2.47000e+01, 5.80450e+00, 3.75440e+00],\n",
       "       [1.45000e+02, 2.20000e+01, 2.43000e+01, 6.63390e+00, 3.54780e+00],\n",
       "       [1.60000e+02, 2.25000e+01, 2.53000e+01, 7.03340e+00, 3.82030e+00],\n",
       "       [1.40000e+02, 2.25000e+01, 2.50000e+01, 6.55000e+00, 3.32500e+00],\n",
       "       [1.60000e+02, 2.25000e+01, 2.50000e+01, 6.40000e+00, 3.80000e+00],\n",
       "       [1.69000e+02, 2.40000e+01, 2.72000e+01, 7.53440e+00, 3.83520e+00],\n",
       "       [1.61000e+02, 2.34000e+01, 2.67000e+01, 6.91530e+00, 3.63120e+00],\n",
       "       [2.00000e+02, 2.35000e+01, 2.68000e+01, 7.39680e+00, 4.12720e+00],\n",
       "       [1.80000e+02, 2.52000e+01, 2.79000e+01, 7.08660e+00, 3.90600e+00],\n",
       "       [2.90000e+02, 2.60000e+01, 2.92000e+01, 8.87680e+00, 4.49680e+00],\n",
       "       [2.72000e+02, 2.70000e+01, 3.06000e+01, 8.56800e+00, 4.77360e+00],\n",
       "       [3.90000e+02, 3.17000e+01, 3.50000e+01, 9.48500e+00, 5.35500e+00],\n",
       "       [2.70000e+02, 2.60000e+01, 2.87000e+01, 8.38040e+00, 4.24760e+00],\n",
       "       [2.70000e+02, 2.65000e+01, 2.93000e+01, 8.14540e+00, 4.24850e+00],\n",
       "       [3.06000e+02, 2.80000e+01, 3.08000e+01, 8.77800e+00, 4.68160e+00],\n",
       "       [5.40000e+02, 3.10000e+01, 3.40000e+01, 1.07440e+01, 6.56200e+00],\n",
       "       [8.00000e+02, 3.64000e+01, 3.96000e+01, 1.17612e+01, 6.57360e+00],\n",
       "       [1.00000e+03, 4.00000e+01, 4.35000e+01, 1.23540e+01, 6.52500e+00],\n",
       "       [5.50000e+01, 1.47000e+01, 1.65000e+01, 6.84750e+00, 2.32650e+00],\n",
       "       [6.00000e+01, 1.55000e+01, 1.74000e+01, 6.57720e+00, 2.31420e+00],\n",
       "       [9.00000e+01, 1.77000e+01, 1.98000e+01, 7.40520e+00, 2.67300e+00],\n",
       "       [1.20000e+02, 1.90000e+01, 2.13000e+01, 8.39220e+00, 2.91810e+00],\n",
       "       [1.50000e+02, 2.00000e+01, 2.24000e+01, 8.89280e+00, 3.29280e+00],\n",
       "       [1.40000e+02, 2.07000e+01, 2.32000e+01, 8.53760e+00, 3.29440e+00],\n",
       "       [1.70000e+02, 2.07000e+01, 2.32000e+01, 9.39600e+00, 3.41040e+00],\n",
       "       [1.45000e+02, 2.15000e+01, 2.41000e+01, 9.73640e+00, 3.15710e+00],\n",
       "       [2.00000e+02, 2.30000e+01, 2.58000e+01, 1.03458e+01, 3.66360e+00],\n",
       "       [2.73000e+02, 2.50000e+01, 2.80000e+01, 1.10880e+01, 4.14400e+00],\n",
       "       [3.00000e+02, 2.60000e+01, 2.90000e+01, 1.13680e+01, 4.23400e+00],\n",
       "       [5.90000e+00, 8.40000e+00, 8.80000e+00, 2.11200e+00, 1.40800e+00],\n",
       "       [3.20000e+01, 1.37000e+01, 1.47000e+01, 3.52800e+00, 1.99920e+00],\n",
       "       [4.00000e+01, 1.50000e+01, 1.60000e+01, 3.82400e+00, 2.43200e+00],\n",
       "       [5.15000e+01, 1.62000e+01, 1.72000e+01, 4.59240e+00, 2.63160e+00],\n",
       "       [7.00000e+01, 1.74000e+01, 1.85000e+01, 4.58800e+00, 2.94150e+00],\n",
       "       [1.00000e+02, 1.80000e+01, 1.92000e+01, 5.22240e+00, 3.32160e+00],\n",
       "       [7.80000e+01, 1.87000e+01, 1.94000e+01, 5.19920e+00, 3.12340e+00],\n",
       "       [8.00000e+01, 1.90000e+01, 2.02000e+01, 5.63580e+00, 3.05020e+00],\n",
       "       [8.50000e+01, 1.96000e+01, 2.08000e+01, 5.13760e+00, 3.03680e+00],\n",
       "       [8.50000e+01, 2.00000e+01, 2.10000e+01, 5.08200e+00, 2.77200e+00],\n",
       "       [1.10000e+02, 2.10000e+01, 2.25000e+01, 5.69250e+00, 3.55500e+00],\n",
       "       [1.15000e+02, 2.10000e+01, 2.25000e+01, 5.91750e+00, 3.30750e+00],\n",
       "       [1.25000e+02, 2.10000e+01, 2.25000e+01, 5.69250e+00, 3.66750e+00],\n",
       "       [1.30000e+02, 2.13000e+01, 2.28000e+01, 6.38400e+00, 3.53400e+00],\n",
       "       [1.20000e+02, 2.20000e+01, 2.35000e+01, 6.11000e+00, 3.40750e+00],\n",
       "       [1.20000e+02, 2.20000e+01, 2.35000e+01, 5.64000e+00, 3.52500e+00],\n",
       "       [1.30000e+02, 2.20000e+01, 2.35000e+01, 6.11000e+00, 3.52500e+00],\n",
       "       [1.35000e+02, 2.20000e+01, 2.35000e+01, 5.87500e+00, 3.52500e+00],\n",
       "       [1.10000e+02, 2.20000e+01, 2.35000e+01, 5.52250e+00, 3.99500e+00],\n",
       "       [1.30000e+02, 2.25000e+01, 2.40000e+01, 5.85600e+00, 3.62400e+00],\n",
       "       [1.50000e+02, 2.25000e+01, 2.40000e+01, 6.79200e+00, 3.62400e+00],\n",
       "       [1.45000e+02, 2.27000e+01, 2.42000e+01, 5.95320e+00, 3.63000e+00],\n",
       "       [1.50000e+02, 2.30000e+01, 2.45000e+01, 5.21850e+00, 3.62600e+00],\n",
       "       [1.70000e+02, 2.35000e+01, 2.50000e+01, 6.27500e+00, 3.72500e+00],\n",
       "       [2.25000e+02, 2.40000e+01, 2.55000e+01, 7.29300e+00, 3.72300e+00],\n",
       "       [1.45000e+02, 2.40000e+01, 2.55000e+01, 6.37500e+00, 3.82500e+00],\n",
       "       [1.88000e+02, 2.46000e+01, 2.62000e+01, 6.73340e+00, 4.16580e+00],\n",
       "       [1.80000e+02, 2.50000e+01, 2.65000e+01, 6.43950e+00, 3.68350e+00],\n",
       "       [1.97000e+02, 2.56000e+01, 2.70000e+01, 6.56100e+00, 4.23900e+00],\n",
       "       [2.18000e+02, 2.65000e+01, 2.80000e+01, 7.16800e+00, 4.14400e+00],\n",
       "       [3.00000e+02, 2.73000e+01, 2.87000e+01, 8.32300e+00, 5.13730e+00],\n",
       "       [2.60000e+02, 2.75000e+01, 2.89000e+01, 7.16720e+00, 4.33500e+00],\n",
       "       [2.65000e+02, 2.75000e+01, 2.89000e+01, 7.05160e+00, 4.33500e+00],\n",
       "       [2.50000e+02, 2.75000e+01, 2.89000e+01, 7.28280e+00, 4.56620e+00],\n",
       "       [2.50000e+02, 2.80000e+01, 2.94000e+01, 7.82040e+00, 4.20420e+00],\n",
       "       [3.00000e+02, 2.87000e+01, 3.01000e+01, 7.58520e+00, 4.63540e+00],\n",
       "       [3.20000e+02, 3.00000e+01, 3.16000e+01, 7.61560e+00, 4.77160e+00],\n",
       "       [5.14000e+02, 3.28000e+01, 3.40000e+01, 1.00300e+01, 6.01800e+00],\n",
       "       [5.56000e+02, 3.45000e+01, 3.65000e+01, 1.02565e+01, 6.38750e+00],\n",
       "       [8.40000e+02, 3.50000e+01, 3.73000e+01, 1.14884e+01, 7.79570e+00],\n",
       "       [6.85000e+02, 3.65000e+01, 3.90000e+01, 1.08810e+01, 6.86400e+00],\n",
       "       [7.00000e+02, 3.60000e+01, 3.83000e+01, 1.06091e+01, 6.74080e+00],\n",
       "       [7.00000e+02, 3.70000e+01, 3.94000e+01, 1.08350e+01, 6.26460e+00],\n",
       "       [6.90000e+02, 3.70000e+01, 3.93000e+01, 1.05717e+01, 6.36660e+00],\n",
       "       [9.00000e+02, 3.90000e+01, 4.14000e+01, 1.11366e+01, 7.49340e+00],\n",
       "       [6.50000e+02, 3.90000e+01, 4.14000e+01, 1.11366e+01, 6.00300e+00],\n",
       "       [8.20000e+02, 3.90000e+01, 4.13000e+01, 1.24313e+01, 7.35140e+00],\n",
       "       [8.50000e+02, 4.00000e+01, 4.23000e+01, 1.19286e+01, 7.10640e+00],\n",
       "       [9.00000e+02, 4.00000e+01, 4.25000e+01, 1.17300e+01, 7.22500e+00],\n",
       "       [1.01500e+03, 4.00000e+01, 4.24000e+01, 1.23808e+01, 7.46240e+00],\n",
       "       [8.20000e+02, 4.00000e+01, 4.25000e+01, 1.11350e+01, 6.63000e+00],\n",
       "       [1.10000e+03, 4.20000e+01, 4.46000e+01, 1.28002e+01, 6.86840e+00],\n",
       "       [1.00000e+03, 4.30000e+01, 4.52000e+01, 1.19328e+01, 7.27720e+00],\n",
       "       [1.10000e+03, 4.30000e+01, 4.55000e+01, 1.25125e+01, 7.41650e+00],\n",
       "       [1.00000e+03, 4.35000e+01, 4.60000e+01, 1.26040e+01, 8.14200e+00],\n",
       "       [1.00000e+03, 4.40000e+01, 4.66000e+01, 1.24888e+01, 7.59580e+00],\n",
       "       [2.00000e+02, 3.23000e+01, 3.48000e+01, 5.56800e+00, 3.37560e+00],\n",
       "       [3.00000e+02, 3.40000e+01, 3.78000e+01, 5.70780e+00, 4.15800e+00],\n",
       "       [3.00000e+02, 3.50000e+01, 3.88000e+01, 5.93640e+00, 4.38440e+00],\n",
       "       [3.00000e+02, 3.73000e+01, 3.98000e+01, 6.28840e+00, 4.01980e+00],\n",
       "       [4.30000e+02, 3.80000e+01, 4.05000e+01, 7.29000e+00, 4.57650e+00],\n",
       "       [3.45000e+02, 3.85000e+01, 4.10000e+01, 6.39600e+00, 3.97700e+00],\n",
       "       [4.56000e+02, 4.25000e+01, 4.55000e+01, 7.28000e+00, 4.32250e+00],\n",
       "       [5.10000e+02, 4.25000e+01, 4.55000e+01, 6.82500e+00, 4.45900e+00],\n",
       "       [5.40000e+02, 4.30000e+01, 4.58000e+01, 7.78600e+00, 5.12960e+00],\n",
       "       [5.00000e+02, 4.50000e+01, 4.80000e+01, 6.96000e+00, 4.89600e+00],\n",
       "       [5.67000e+02, 4.60000e+01, 4.87000e+01, 7.79200e+00, 4.87000e+00],\n",
       "       [7.70000e+02, 4.80000e+01, 5.12000e+01, 7.68000e+00, 5.37600e+00],\n",
       "       [9.50000e+02, 5.17000e+01, 5.51000e+01, 8.92620e+00, 6.17120e+00],\n",
       "       [1.25000e+03, 5.60000e+01, 5.97000e+01, 1.06863e+01, 6.98490e+00],\n",
       "       [1.60000e+03, 6.00000e+01, 6.40000e+01, 9.60000e+00, 6.14400e+00],\n",
       "       [1.55000e+03, 6.00000e+01, 6.40000e+01, 9.60000e+00, 6.14400e+00],\n",
       "       [1.65000e+03, 6.34000e+01, 6.80000e+01, 1.08120e+01, 7.48000e+00],\n",
       "       [6.70000e+00, 9.80000e+00, 1.08000e+01, 1.73880e+00, 1.04760e+00],\n",
       "       [7.50000e+00, 1.05000e+01, 1.16000e+01, 1.97200e+00, 1.16000e+00],\n",
       "       [7.00000e+00, 1.06000e+01, 1.16000e+01, 1.72840e+00, 1.14840e+00],\n",
       "       [9.70000e+00, 1.10000e+01, 1.20000e+01, 2.19600e+00, 1.38000e+00],\n",
       "       [9.80000e+00, 1.12000e+01, 1.24000e+01, 2.08320e+00, 1.27720e+00],\n",
       "       [8.70000e+00, 1.13000e+01, 1.26000e+01, 1.97820e+00, 1.28520e+00],\n",
       "       [1.00000e+01, 1.18000e+01, 1.31000e+01, 2.21390e+00, 1.28380e+00],\n",
       "       [9.90000e+00, 1.18000e+01, 1.31000e+01, 2.21390e+00, 1.16590e+00],\n",
       "       [9.80000e+00, 1.20000e+01, 1.32000e+01, 2.20440e+00, 1.14840e+00],\n",
       "       [1.22000e+01, 1.22000e+01, 1.34000e+01, 2.09040e+00, 1.39360e+00],\n",
       "       [1.34000e+01, 1.24000e+01, 1.35000e+01, 2.43000e+00, 1.26900e+00],\n",
       "       [1.22000e+01, 1.30000e+01, 1.38000e+01, 2.27700e+00, 1.25580e+00],\n",
       "       [1.97000e+01, 1.43000e+01, 1.52000e+01, 2.87280e+00, 2.06720e+00],\n",
       "       [1.99000e+01, 1.50000e+01, 1.62000e+01, 2.93220e+00, 1.87920e+00]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 독립변수 특성 데이터만 추출\n",
    "predict_data = fish[['Weight','Length','Diagonal','Height','Width']].to_numpy()\n",
    "predict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0817c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_scaled = ss.transform(predict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ae19f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diagonal</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "      <th>Species</th>\n",
       "      <th>Species_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>242.0</td>\n",
       "      <td>25.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.5200</td>\n",
       "      <td>4.0200</td>\n",
       "      <td>Bream</td>\n",
       "      <td>Bream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>290.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>31.2</td>\n",
       "      <td>12.4800</td>\n",
       "      <td>4.3056</td>\n",
       "      <td>Bream</td>\n",
       "      <td>Bream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>340.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>12.3778</td>\n",
       "      <td>4.6961</td>\n",
       "      <td>Bream</td>\n",
       "      <td>Bream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>363.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>12.7300</td>\n",
       "      <td>4.4555</td>\n",
       "      <td>Bream</td>\n",
       "      <td>Bream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>430.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.4440</td>\n",
       "      <td>5.1340</td>\n",
       "      <td>Bream</td>\n",
       "      <td>Bream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>12.2</td>\n",
       "      <td>12.2</td>\n",
       "      <td>13.4</td>\n",
       "      <td>2.0904</td>\n",
       "      <td>1.3936</td>\n",
       "      <td>Smelt</td>\n",
       "      <td>Smelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>13.4</td>\n",
       "      <td>12.4</td>\n",
       "      <td>13.5</td>\n",
       "      <td>2.4300</td>\n",
       "      <td>1.2690</td>\n",
       "      <td>Smelt</td>\n",
       "      <td>Smelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>12.2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>2.2770</td>\n",
       "      <td>1.2558</td>\n",
       "      <td>Smelt</td>\n",
       "      <td>Smelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>19.7</td>\n",
       "      <td>14.3</td>\n",
       "      <td>15.2</td>\n",
       "      <td>2.8728</td>\n",
       "      <td>2.0672</td>\n",
       "      <td>Smelt</td>\n",
       "      <td>Smelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>19.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>2.9322</td>\n",
       "      <td>1.8792</td>\n",
       "      <td>Smelt</td>\n",
       "      <td>Smelt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Weight  Length  Diagonal   Height   Width Species Species_pred\n",
       "0     242.0    25.4      30.0  11.5200  4.0200   Bream        Bream\n",
       "1     290.0    26.3      31.2  12.4800  4.3056   Bream        Bream\n",
       "2     340.0    26.5      31.1  12.3778  4.6961   Bream        Bream\n",
       "3     363.0    29.0      33.5  12.7300  4.4555   Bream        Bream\n",
       "4     430.0    29.0      34.0  12.4440  5.1340   Bream        Bream\n",
       "..      ...     ...       ...      ...     ...     ...          ...\n",
       "154    12.2    12.2      13.4   2.0904  1.3936   Smelt        Smelt\n",
       "155    13.4    12.4      13.5   2.4300  1.2690   Smelt        Smelt\n",
       "156    12.2    13.0      13.8   2.2770  1.2558   Smelt        Smelt\n",
       "157    19.7    14.3      15.2   2.8728  2.0672   Smelt        Smelt\n",
       "158    19.9    15.0      16.2   2.9322  1.8792   Smelt        Smelt\n",
       "\n",
       "[159 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 예측을 통해 \"class_pred\" 컬럼 신규 생성하여 \n",
    "# 예측 데이터 결과 확인하기\n",
    "result_predict = sc.predict(predict_scaled)\n",
    "\n",
    "fish_pred = fish[['Weight','Length','Diagonal','Height','Width']]\n",
    "fish_pred[\"Species\"] = fish[\"Species\"]\n",
    "fish_pred[\"Species_pred\"] = result_predict\n",
    "fish_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52c32930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 갯수[159]건 중에, 정답갯수[152]건, 오답 갯수[7]건\n"
     ]
    }
   ],
   "source": [
    "### 정답 갯수와 오답 갯수 확인하기\n",
    "o_cnt = len(fish_pred[(fish_pred[\"Species\"] == fish_pred[\"Species_pred\"])])\n",
    "o_cnt\n",
    "\n",
    "x_cnt = len(fish_pred[(fish_pred[\"Species\"] != fish_pred[\"Species_pred\"])])\n",
    "x_cnt\n",
    "\n",
    "sum_cnt = len(fish_pred)\n",
    "sum_cnt \n",
    "\n",
    "print(\"총 갯수[{}]건 중에, 정답갯수[{}]건, 오답 갯수[{}]건\".format(sum_cnt, o_cnt, x_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d8e6295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 100.0% 중 정답률[95.6%], 오답률[4.4%]\n"
     ]
    }
   ],
   "source": [
    "### 정답률과 오답률 확인하기\n",
    "import numpy as np\n",
    "\n",
    "o_p = np.round(o_cnt / sum_cnt * 100, 2)\n",
    "x_p = np.round(x_cnt / sum_cnt * 100, 2)\n",
    "sum_p = o_p + x_p\n",
    "\n",
    "print(\"총 {}% 중 정답률[{}%], 오답률[{}%]\".format(sum_p, o_p, x_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e511cdfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2288ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_kernel",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
